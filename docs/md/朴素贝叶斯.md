# 1. 朴素贝叶斯

* 贝叶斯理论:
    * 现在有一个数据集，它由两类数据组成
    
    ![朴素贝叶斯](https://note.youdao.com/yws/api/personal/file/WEB43d4f6d681245e782e2a7cab4ec83386?method=download&shareKey=7410ef973c347696828235bfa773dee3)

    * 现在用p1(x,y)表示数据点(x,y)属于类别1(图中圆点表示的类别)的概率,用p2(x,y)属于类别2(图中三角形表示的类别)的概率,那么对于一个新的数据点(x,y),可以用下面的规则来判断它的类别:
        * 如果p1(x,y)>p2(x,y),那么类别为1
        * 如果p2(x,y)>p1(x,y),那么类别为2

    * 也就是说,我们会选择高概率对应的类别,这就是贝叶斯决策理论的核心思想,即选择具有最高概率的决策

* 朴素贝叶斯场景:
    * 机器学习的一个重要应用就是文档的自动分类
    * 在文档分类中,整个文档(如一封电子邮件)是实例,而电子邮件中的某些元素则构成特征,我们可以观察文档中出现的词,并把每个词作为一个特征,而每个词的出现或者不出现作为该特征的值,这样得到的特征数目就会跟词汇表中的词的数目一样多

## 2. 朴素贝叶斯原理

* 朴素贝叶斯工作原理

```
提取所有文档中的词条并进行去重
获取文档中的所有类别
计算每个类别中的文档数目
对每篇训练文档:
    对每个类别:
        如果词条出现在文档中-->增加该词条的计数值(for循环或矩阵相加)
        增加所有词条的计数值(此类别下词条总数)
对每个类别:
    对每个词条:
        将该词条的数目除以总词条数目得到的条件概率(P(词条|类别))
返回该文档属于每个类别的条件概率(P(类别|文档的所有词条))
```

* 朴素贝叶斯算法特点:
    * 优点:在数据较少的情况下仍然有效,可以处理多类别的问题
    * 缺点:对于输入数据的准备方式较为敏感
    * 适用数据类型:标称型数据

## 3.项目案例