# 训练误差和测试误差
* 机器学习的目的是使学得的模型不仅对**已知数据**还对**未知数据**都有很好的预测能力

* 训练集：相当于课后练习题，用来日常知识巩固**即训练模型**，对应**训练误差**

* 验证集：相当于小测，用来纠正和强化所学知识**即选择模型**，对应**测试误差**

* 测试集：相当于期末考试，用来最终评估学习效果，对应**泛化误差的近似**

* 当损失函数给定时，基于损失函数模型的训练误差（也叫经验误差）和测试误差，可用于评价学习方法
    * 训练误差（训练集上）：若训练误差过大，则没法很好学习到训练集中的规律，存在**欠拟合**

    * 测试误差（测试集上）：测试误差的大小反映了学习方法对未知的测试数据集的预测能力，测试误差小的方法有着更好的预测能力（也叫泛化能力）

    * 泛化误差（未知数据上）：指模型在未知记录上的期望误差，即在训练集上没见过的数据的错分样本比率；样本集划分时如训练集和测试集的数据没有交集，此时训练误差基本等于泛化误差

# 过拟合与模型选择
* 过拟合：不知道新样本特征，仅追求经验误差最小化，导致将训练样本自身的特点当作所有样本的一般性质，从而造成泛化性能下降

    ![Alt text](image-163.png)    

* 模型选择的典型方法是**正则化**。正则化是**损失结构风险最小**策略的实现，是在经验分析上加一个正则化项和罚项
    * 正则化项一般是模型复杂度的单调递增函数，**模型越杂正则化值越大**

    ![Alt text](image-166.png)

    ![Alt text](image-170.png)   

* 模型验证方法
    1. 留出法
        * 直接将数据集划分为两个互斥集合，训练集和测试集划分尽可能保持数据分布一致性
        
        * 一般进行若干次随机划分，重复实验取平均值
        
        * 训练/测试样本比例通常为2:1~4:1

    2. 交叉验证法
        * k折交叉验证：将数据集分层采样划分为k个大小相似的互斥子集，每次用k-1个子集的并集作为训练集，余下子集作为测试集，最终返回k个测试结果的均值，k常用的取值是10

            ![Alt text](image-171.png)

        * 假设数据集D包含m个样本，若令k=m，则得到留一法：
            * 不受随机样本划分方式的影响，结果往往比较准确

            * 当数据集较大时，计算开销难以忍受
    
    3. 自助法
        * 设样本全集容量为m，对样本全集有放回采样m次得到自主抽样样本集D'

            * 有的样本可能被多次重复抽到，而也有的样本一次也没被抽到（概率约为1/3），这些没被抽到的样本可被用来当作测试集

                ![Alt text](image-172.png)

            * 优势：可以获取更多的、超出原样本容量的样本，在针对小样本集或难以有效划分训练集和样本集非常有用

            * 缺点：自助法产生的训练集改变了初始数据集的分布，会引入估计偏差

# 性能度量

## 均方误差
* 性能度量是衡量模型泛化能力的评价标准，反映的任务需求，不同的性能度量往往导致不同的评判结果

![Alt text](image-208.png)

## 错误率和精度
* 对于分类任务，错误率和精度是最常用的两种性能度量：

![Alt text](image-209.png)

* Ⅱ(a=b)是指如果a=b则等于1，否则为0

## 查准率和查全率

![Alt text](image-210.png)

* 查准率：`P=TP/(TP+FP)`预测对于真例的准确度（所有判定为男中，确实为男的概率）

* 查全率：`P=TP/(TP+FN)`预测对于真例的全面度（所有确实为男中，判定为男的概率）

## P-R曲线
* 根据学习器的预测结果按正例可能性大小对样例进行排序，并逐个把样本作为正例进行预测，则可以得到**查准率-查全率曲线（P-R曲线）**

```
假设开发一个疾病检测模型，该模型用于预测一个人是否患有某种罕见疾病

测试样本：
    有100个样本是患有该疾病的真正病例（正例）
    有900个样本是健康人的数据（负例）

模型对每个样本进行了预测，为每个样本估计患有疾病的概率

按照预测的患病概率从高到低对样本进行排序

将逐个把样本作为正例进行预测，并计算在每个阈值下的查准率和查全率

从排在前面的样本（概率最高）开始，将其作为正例，计算查准率和查全率

然后逐个添加下一个样本，再次计算查准率和查全率，直到所有样本都被考虑为正例，得到一系列查准率和查全率的数值

最后将这些数值绘制成曲线，就得到了查准率-查全率曲线（P-R曲线）
```

![Alt text](image-211.png)

* 平衡点是曲线上“查准率=查全率”时的取值，可用于度量P-R曲线有交叉的分类器的性能高低

## F1度量
* 比P-R曲线平衡点更常用的是F1度量：

    ![Alt text](image-212.png)

* 比F1度量更一般的形式Fβ：

    ![Alt text](image-213.png)

## ROC曲线和AUC值
* 根据学习器预测结果对样例排序，并逐个作为正例进行预测，以“假正例率”（对负例把负例预测为正例概率）为横轴，“真正例率”（查全率）为纵轴可得ROC曲线

* 若某个学习器的ROC曲线被另一个学习器的曲线包住，则后者性能优于前者；若曲线交叉，可根据ROC曲线下的面积大小比较，即**AUC值**

![Alt text](image-214.png)

![Alt text](image-215.png)

# 偏差和方差

![Alt text](image-216.png)

![Alt text](image-217.png)  

* 泛化误差可分解为偏差、方差与噪声之和：
    * 偏差度量了学习算法期望预测与真实结果的偏离程度；即**刻画了学习算法本身的拟合能力**

    * 方差度量了同样大小的训练集的变动导致的学习能力的变化；即**刻画了数据扰动所造成的影响

    * 噪声表达了在当前任务上任何算法所能达到的期望泛化误差的下界；即**刻画了学习问题本身的难度**
    