## 1. 决策树

* 决策树的定义:分类决策树是一种对实例进行分类的树型结构,决策树由结点和有向边组成,结点内部结点和叶结点,内部结点表示一个特征或属性,叶结点表示一个类
* 用决策树对需要测试的实例进行分类:从根节点开始,对实例的某一特征进行测试,根据测试结果,将实例分配到其子结点,这时每一个子结点对应着该特征的一个取值,如此递归地对实例进行测试并分配,直至达到叶结点,最后将实例分配到叶结点的类中

## 2. 决策树原理

* 信息熵&信息增益:
    * 熵:熵指体系的混乱程度,在不同的学科中也有引申出更为具体的定义,是各领域十分重要的参量
    * 信息论中的熵(香农熵):是一种信息的度量方式,表示信息的混乱程度,也就是说,信息越有序,信息熵越低
    * 信息增益:在划分数据集前后信息发生的变化称为信息增益

* 如何构造一个决策树?我们使用createBranch()方法

```
def createBranch():    #此处运用了迭代的思想
    检测数据集中的所有元素的分类标签是否相同:
        if so return 类标签
        else:
            寻找划分数据集的最好特征(划分后信息熵最小,也就是信息增益最大的特征)
            划分数据集
            创建分支结点
                for 每个划分的子集
                    调用函数 createBranch (创建分支的函数) 并增加返回结果到分支结点中
            return 分支结点
```

* 算法特点:
    * 优点:计算复杂度不高,输出结果容易理解,数据丢失也能跑,可以处理不相关特征
    * 缺点:容易过拟合
    * 适用数据类型:数值型和标称型

## 2. 项目案例

* 判断胖瘦

```
import numpy as np
import pydotplus
from six import StringIO
from sklearn import tree
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

def createDataSet():#建立数据集
    data=[]#特征：身高 体重
    labels=[]#标签：胖瘦
    with open('C:/Users/D5/Desktop/data.txt')as ifile:
        for line in ifile:#将文件信息读入data和labels
            tokens=line.strip().split(' ')
            data.append([float(tk) for tk in tokens[:-1]])
            labels.append(tokens[-1])
    x=np.array(data)#将data整合成数组
    labels=np.array(labels)#将labels整合成数组
    y=np.zeros(labels.shape)#初始化存放标签的数组
    y[labels=='fat']=1
    print('data: ',data)
    print('labels: ',labels)
    print('x: ',x)
    print('y: ',y)
    return x,y

def predict_train(x_train,y_train):#预测训练集
    clf= tree.DecisionTreeClassifier(criterion='entropy')#建立决策树分类器
    clf.fit(x_train,y_train)#将训练集进行训练
    print('feature_importances_: %s'%clf.feature_importances_)#特征重要性
    y_pre=clf.predict(x_train)#对训练集进行预测
    print('训练集的预测标签:',y_pre)
    print('训练集的真实标签: ',y_train)
    print('训练集的真实标签和预测标签的平均相等值: ',np.mean(y_pre==y_train))
    return y_pre,clf

def show_precision_reall(x,y,clf,y_train,y_pre):
    answer=clf.predict_proba(x)[:,1]
    target_names=['thin','fat']
    print(classification_report(y, answer, target_names=target_names))
    print(answer)
    print(y)

def show_pdf(clf):
    dot_data=StringIO()
    tree.export_graphviz(clf,out_file=dot_data)
    graph=pydotplus.graph_from_dot_data(dot_data.getvalue())
    graph.write_pdf('C:/Users/D5/Desktop/output.pdf')

if __name__=='__main__':
        x,y=createDataSet()
        print('#已建立数据集\n')

        x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)#test_size:分割比例：测试集占完整数据集的比例
        print('训练集: ',x_train,'标签: ',y_train)
        print('测试集: ',x_test,'标签: ',y_test)
        print('#已划分训练集和测试集\n')

        y_pre,clf=predict_train(x_train,y_train)
        print('决策树已建立\n')

        test=[]
        num_input=input('请输入身高和体重用空格隔开:').split()
        num_input=[int(num) for num in num_input]
        num_input=[num_input[i:i+2] for i in range(0,len(num_input),2)]
        num_input=np.array(num_input)
        pre=clf.predict(num_input)
        for i in pre:
            if i==1:
                print('fat')
            else:
                print('thin')

        show_precision_reall(x,y,clf,num_input,pre)
        show_pdf(clf)
```

* 训练集

```
180 60 thin
175 60 fat
189 70 thin
160 50 fat
166 80 fat
186 100 fat
165 47 thin
198 200 fat
177 188 fat
155 60 fat
173 44 thin
166 80 fat
```